---
title: "Data Mining Final Project"
author: "Johnathan Bowman, Amal Kadri, and Alice Kemp"
date: "Spring 2022"
output: 
  pdf_document: default
---

## Introduction
  The subject of school performance has been heavily researched in the past with most studies coming to the conclusion that household income and racial/ethnic demographics are the most predictive factors of school performance. Students who come from households with predominantly high socioeconomic status tend to perform better than their peers who come from lower socioeconomic circumstances - this trend further aggregates to the school and district level with schools located in neighborhoods of higher socioeconomic status typically outperforming those in poorer areas, as measured by metrics such as standardized test scores, graduation rates, and college acceptance rates. However, in a state as racially diverse as Texas, how well do these trends explain over versus under-performance at the district level? In this report, we will analyze district-level data gathered from the Texas Education Agency during the 2019 to 2020 school year covering student and faculty demographics, SAT/ACT test scores, median household income, enrollment, and graduation rates. From this data, we will identify districts that over or under perform their predicted outcome score and use machine learning techniques to analyze the correlated variables responsible. By doing so, we hope to uncover the key factors that make a district out or under perform other districts with similar demographic makeup. By doing so, we will hopefully deepen our understanding of school performance and use our findings to narrow the achievement gap between districts in Texas and beyond. 

## Methods
  The subject of school performance has been heavily researched in the past with most studies coming to the conclusion that household income and racial/ethnic demographics are the most predictive factors of school performance. Students who come from households with predominantly high socioeconomic status tend to perform better than their peers who come from lower socioeconomic circumstances - this trend further aggregates to the school and district level with schools located in neighborhoods of higher socioeconomic status typically outperforming those in poorer areas, as measured by metrics such as standardized test scores, graduation rates, and college acceptance rates. However, in a state as racially diverse as Texas, how well do these trends explain over versus under-performance at the district level? 
  
## Data
  The Data we used for our analysis was gathered primarily from the TEA, USDA, and the Census. We gathered TEA data on educational outcomes (Graduation Rates, Standardized Test Scores, Attendance, etc.), and school-district-level covariates (Student-Teacher Ratio, Teacher Pay, Disciplinary Activity, School Meals, etc.). We merged these variables onto socioeconomic indicators such as poverty rate, median income, and education levels. This aggregation had to be done at the county level, which means some researcher bias had to be introduced when deciding how to most appropriately aggregate outcomes data gathered at the district level up to the county level. All said, we had 87 covariates for analysis on 8 outcome variables:
* `ERW`: Average SAT evidence-based reading and writing score
* `MATH`: Average SAT mathematics score
* `TOTAL`: Average SAT total score
* `ann_grad_count_1819`: The number of students who graduated during the 2018-19 school year, including the summer of 2019. This count includes 12th grade graduates, as well as graduates from other grades.
* `avg_sat_1819`: The average of SAT total scores (a sum of evidence-based reading and writing and mathematics) for 2018-19 graduates who took the SAT divided by the number of 2018-19 graduating SAT examinees. Total scores for the SAT range from 400 to 1600 for evidence-based reading and writing and mathematics combined. Total score for each examinee is calculated based on the best section scores from all SAT tests taken by the examinee anytime during their high school years.
* `avg_act_1819`: The average of ACT composite scores (an average of English, mathematics, reading, and science), created by summing the composite scores for 2018-19 graduates who took the ACT divided by the number of 2018-19 graduating ACT examinees. Scores on each of the ACT sections range from 1 to 36.
* `Above_Crit_Rate`: Percent of graduating examinees receiving SAT total scores of 1180 or higher
* `Above_TSI_Both_Rate`: Percent of graduating examinees meeting the college-ready graduates TSI criteria for the SAT on both ELA and mathematics
  An unfortunate issue when it comes to using Education data from a data analytics perspective is the issue of "Masking". Because of privacy considerations, schools must take care to not release any data that could be potentially used to identify specific students. As an example, if there are only a handful of Hispanic students in a given school, the school might have to mask any statistics on the racial/ethnic breakdown of educational outcomes in order to prevent the possibility that the data can be easily used to find the scores, economic, or disciplinary status of specific students. In aggregate, this means that there are a significant number of N/As and masked codes that had to be dealt with in order to proceed with the analysis. As a result, our data is biased slightly in favor of being more accurate for schools with larger, more diverse school populations, and may not capture all the useful variation for smaller school districts. However, given that this is a limitation with all publicly available, and our goal was to identify which patterns/abnormalities in the data we *could* see, rather than a more rigorous causal analysis, this seemed to us an acceptable constraint.

## Analysis
To start our analysis, we first merged our data and then created an aggregated "outcome" variable to measure district performance across a variety of metrics including SAT ERW and Math scores, previous year graduation rate, previous year SAT and ACT scores, and percentages of graduating students meeting the college-ready measures for SAT scores. To create this outcome variable, Principle Component Analysis (PCA) of rank 1 was used to reduce the dimensionality of our outcome variables and create one PC of weights that maximizes the variance found in the original outcome data. The resulting PC1 in Table 1 shows relatively large weights from every performance metrics, with the minimal exception of previous year graduation rate. 
  
```{r analysis, echo = FALSE, warning = FALSE, message = FALSE, results = 'asis'}
if (!("librarian" %in% rownames(utils::installed.packages()))) {
  utils::install.packages("librarian")}
librarian::shelf(tidyverse, haven, kableExtra, modelr, rsample, stargazer, randomForest)
load(file = "all_objects.RData")
# load("r_objects/training_data.RData")
testing = read.csv("r_objects/testing.csv")
outcomes_PCA_table = prcomp(testing[,(1:8)], scale=TRUE, rank=1)
data.frame(outcomes_PCA_table$rotation) %>% kbl(booktabs = T, format = 'latex', digits = 4, caption = "PCA of performance metrics") %>% kable_classic(full_width = F, html_font = "Cambria") %>% kable_styling(latex_options = 'hold_position')
```
  First, we fit the loadings of PC1 on to our original district-level data resulting in a singular outcome performance variable. We then create a simple linear OLS regression of our new weighted outcome variable on a selection of covariates believed to be most indicative of performance based on previous literature. These features included median household income measured as a percent of the statewide median, the child poverty rate in each county, average faculty salary, along with percentages for student population by race (Black, Hispanic, White, Asian, Native American, Pacific Islander, and multi-racial). Child poverty percent effects has both the resources a child has access to and is associated with other deviant behavior like truancy. Percent state median income defines the percent of the mean income for the county of the states median income. For instance, a county with 1.5 is a county with a mean income 50% higher than the state median. Average school salary describes the amount of resources that are going to a district. After fitting the OLS model, we then use the residuals, or the difference between predicted performance versus actual performance, as the outcome variable for a random forest model. This machine learning method uses the aggregate results of "n" individual, uncorrelated decision trees to minimize overfitting of any singular tree. We then further our analysis by running separate random forest models on the positive and negative residuals found in our original OLS model, with positive residuals representing districts that over perform relative to their predicted outcome, and negative residuals representing districts that under perform. In doing so, we hope to isolate any variables that affect over performing versus under performing districts. For all random forest models, root mean squared error was calculated using 80% train-test splits, and results are visualized using partial dependence plots of the top five most important variables to each model. 

## Findings
### OLS Model
 As observed in the model results in Table 2, we find that percent of state median household income and average school salary are highly statistically significant in predicting district performance. This result supports other studies on the subject, however, this does not explain why some school districts who would be predicted to perform at a certain level do not. These districts are represented in the residuals of our linear model, which we will next use as the outcome variable in a series of machine learning models. 

```{r ols, echo = FALSE, message=FALSE, warning = FALSE, results = 'asis'}
load("r_objects/lin_mod.RData")
stargazer(lin_mod, header = FALSE, title = "Table 2: Linear Model")
```

### Decision Tree
For our decision tree and random forest models, we first scaled our variables that used counts as to normalize based on student enrollment in each district. Then, a decision tree was fitted with our residuals from the OLS model as the outcome variable of interest. As seen in Figure 1, the most important split was the scaled share of students in a district eligible for free meals, which is based on a student's household income level. For over-performing districts with positive residuals, we see a share less than 31%, indicating that these districts tend to have higher average household income. Over-performing districts with a predicted average residual of 0.38 also have lower un-allocated expenditure levels, scaled per student, and higher percentages of bilingual students. For districts with negative residuals, we find somewhat contradictory results, with RUC codes of both 4 and 9 leading to some of the most under-performing districts. RUC codes measure how rural a district is, with 1 being the most urban and 9 being the most rural. Thus, according to our decision tree, the most rural districts and those in the middle tend to be the most under-performing. Finally, smaller shares of discipline records per student appears to predict better performing districts, however the predicted residuals for both sides of this node are negative. Since we are concerned with overfitting our data, we will next use random forest models to minimize this risk. 

```{r tree, file = "code/decision_tree.R", echo = FALSE, message=FALSE, warning=FALSE, results = 'asis'}
load("r_objects/tree_vip.Rdata")
load("r_objects/tree.Rdata")
rpart.plot(ed_tree, type = 2, digits = 2, varlen = -15, main = "Fig 1: CART for Predicted Residuals")

tree_vip_top %>% kable(booktabs = T, format = "latex", caption = "CART: Variable Importance") %>% kable_classic(full_width = F, html_font = "Cambria") %>% kable_styling(latex_options = 'hold_position')
```

### Random Forest
Our next step in modeling over and under performing school districts was to use a random forest on the residuals found in the linear OLS regression. Using a random forest with all features as possible splits, we created a model with a root mean squared error of 1.17, lower than the error from the CART regression above. The most important variables selected in the new random forest model were the average students eligible for the free meal program, the percent of students in career/tech programs, the rural index of the district, the average salary for district employees working in professional services, and the district's teacher turnover rate. Looking at partial dependence plots of these top five features, we can interpret the marginal effects of increasing these feature values on the residuals found in the OLS model, thus giving an easily interpretable estimate of how certain district characteristics lead to over and under performance.  
  The first partial dependence plot demonstrates the negative correlation between the number of students eligible for free meals, based on their household income, and the predicted residuals. The graph implies that districts with relatively low (0 to 0.25) shares of students eligible for free meals tend to have positive residuals, or over performance. However, as this share increases, the residuals become more negative, implying that districts with larger shares of students eligible for free meals tend to under-perform their predicted performance. Moving on to the share of students in career/tech programs, we observe that districts with larger shares actually tend to under-perform their predicted outcomes thus implying a negative correlation. Next, we look at the partial dependence of RUC code, which measures how rural a district is with 1 being the most urban and 9 being the most rural. We find varying results for this variable, with all codes correlated with negative predicted residuals - further analysis in later sections of this report will attempt to uncover the true correlation. Moving on to the average salary for professional services, we find results for negative predicted residuals only and find that there is an interesting dependence with the marginal effect of increasing salary first moving predicted residuals towards zero before dropping steeply. Overall, average professional services salaries in a district above $75,000 appear to be correlated with under-performing districts, although this trend bottoms out quickly. Lastly, we observe the partial dependence of teacher turnover rate with lower rates appearing to be correlate with over-performing districts, while higher rates above approximately 18% being increasingly negatively correlated with under-performance. 


```{r rf_all, echo = FALSE, message = FALSE, warning = FALSE, results = 'asis'}
## RF ALL 
load("r_objects/rf_vip.Rdata")
load("r_objects/rf.Rdata")

# vip table
importance_table %>% kbl(booktabs = T, format = "latex", caption = "Random Forest: Variable Importance for All Districts") %>% kable_classic(full_width = F, html_font = "Cambria") %>% kable_styling(latex_options = 'hold_position')

# top 5 partial dependence plots 
feats_all = importance_table[,1]
par(mfrow = c(3,2))
for (i in feats_all){
plot = pdp::partial(rf, pred.var = i, plot = TRUE, plot.engine = "ggplot2") + 
  ggtitle(paste("Partial Dependence Plot of ", i)) + 
  xlab(paste(i)) + 
  ylab("Predicted Resid")
print(plot)
}
```
  To further deepen the model, we next split our data into districts with positive and negative residuals, representing districts that over performed relative to their predicted performance and those who under performed relative to their predicted performance. We used random forests of 50 trees to identify the features most predictive of an over or under performing district and created variable importance plots to visualize the partial dependence of the most important variables for over and under performing districts. 
  For the over performing school districts with positive residuals, we found the most important feature to be RUC code, a measure of how rural versus urban a county is on a scale from 1 to 9, with 1 being the most urban and 9 being the most rural. As seen in the figure below, we observe that there is overall in positive and increasing effect of RUC on over-performance, with more rural districts overperforming by a higher margin than more urban districts. This seems to contradict what our predictions would be regarding higher performing urban districts in major metropolitan districts, however, since there a many more schools within an urban district versus an urban district, and our performance metrics are aggregated to the district level, we may simply be seeing a sampling bias towards these rural districts. The next most important variable was the county unemployment level in 2019 - to avoid any confounding effects due to the COVID-19 pandemic in 2020, we used unemployment from the previous year. From the plot below, we observe that the most over-performing districts have the lowest rates of unemployment, which supports the theory that districts with households of higher socioeconomic tend to perform better than those with worse socioeconomic circumstances. Ostensibly, higher levels of employment are also correlate with more stable household environments, which supports higher student performance. Moving on, we find that the share of a district's revenue that comes from local district and city funds versus state and federal funds tend has a positive correlation with overperformance. 

### Overperforming Districts
```{r rf_over, file = "code/randomForest_new.R", results = 'asis', message = FALSE, echo = FALSE, warning = FALSE}
load("r_objects/rf_over_vip.Rdata")
load("r_objects/rf_over.Rdata")

# vip table
rf_over_vip %>% kbl(booktabs = T, format = "latex", caption = "Random Forest: Variable Importance for Overperforming Districts") %>% kable_classic(full_width = F, html_font = "Cambria") %>% kable_styling(latex_options = 'hold_position')

# top 5 partial dependence plots 
feats_over = rf_over_vip[,1]
par(mfrow = c(3,2))
for (i in feats_over){
plot = pdp::partial(rf_over, pred.var = i, plot = TRUE, plot.engine = "ggplot2") + 
  ggtitle(paste("Partial Dependence Plot of ", i)) + 
  xlab(paste(i)) + 
  ylab("Predicted Resid")
print(plot)
}
```

### Underperforming Districts
```{r rf_under, file = "code/randomForest_new.R", results = 'asis', message = FALSE, echo = FALSE, warning = FALSE}
load("r_objects/rf_under_vip.Rdata")

# vip table
rf_under_vip %>% kbl(booktabs = T, format = "latex", caption = "Random Forest: Variable Importance for Underperforming Districts") %>% kable_classic(full_width = F, html_font = "Cambria") %>% kable_styling(latex_options = 'hold_position')

# top 5 partial dependence plots 
feats = rf_under_vip[,1]
par(mfrow = c(3,2))
for (i in feats){
plot = pdp::partial(rf_under, pred.var = i, plot = TRUE, plot.engine = "ggplot2") + 
  ggtitle(paste("Partial Dependence Plot of ", i)) + 
  xlab(paste(i)) + 
  ylab("Predicted Resid")
print(plot)
}
```


## Conclusion

  A severe limitation to the data was the masking of many of the student fields. The reason the data was masked is because it was available to the public. If certain values were made available it would give anyone the means to impute the identities of students who are in these groups. An unfortunate side effect is the elimination of many fields which could have been descriptive for controlling and predicting education outcome. This included but is not limited to fields like immigration or migrant status, dyslexia, foster care status, homelessness, or military connected. These were among the fields which had to be removed in the cleaning process due to NA values so the variation in these fields was not able to be accounted for. A massive improvement to this study would be to conduct it with access to this masked data, which may need to occur within a state regulatory institution which has clearance to view the information. 